import matplotlib.pyplot as plt
import random

# Normal Distribution
x_values = [x / 10 for x in range(-50, 51)]
pdf_values = [normal_pdf(x, mu=0, sigma=1) for x in x_values]
cdf_values = [normal_cdf(x, mu=0, sigma=1) for x in x_values]

# Plot the PDF and CDF of the Normal Distribution
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.plot(x_values, pdf_values)
plt.xlabel('x')
plt.ylabel('Probability Density')
plt.title('Normal Distribution PDF')

plt.subplot(1, 2, 2)
plt.plot(x_values, cdf_values)
plt.xlabel('x')
plt.ylabel('Cumulative Probability')
plt.title('Normal Distribution CDF')

plt.tight_layout()
plt.show()

# Binomial Distribution
n = 20
p = 0.5
num_trials = 1000

# Simulate Binomial trials
binomial_values = [binomial(n, p) for _ in range(num_trials)]

# Count the occurrences of each value
value_counts = [binomial_values.count(k) for k in range(n+1)]

# Plot the Binomial Distribution
plt.bar(range(n+1), value_counts)
plt.xlabel('k')
plt.ylabel('Count')
plt.title('Binomial Distribution')

plt.show()


OR 


from typing import Tuple
import math
from scratch.probability import normal_cdf
from scratch.probability import inverse_normal_cdf

def normal_approximation_to_binomial(n: int, p: float) -> Tuple[float, float]:
    """Returns mu and sigma corresponding to a Binomial(n, p)"""
    mu = p * n
    sigma = math.sqrt(p * (1 - p) * n)
    return mu, sigma

# The normal_cdf is the probability the variable is below a threshold
normal_probability_below = normal_cdf

# It's above the threshold if it's not below the threshold
def normal_probability_above(lo: float, mu: float = 0, sigma: float = 1) -> float:
    """The probability that an N(mu, sigma) is greater than lo."""
    return 1 - normal_cdf(lo, mu, sigma)

# It's between if it's less than hi, but not less than lo
def normal_probability_between(lo: float, hi: float, mu: float = 0, sigma: float = 1) -> float:
    """The probability that an N(mu, sigma) is between lo and hi."""
    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)

# It's outside if it's not between
def normal_probability_outside(lo: float, hi: float, mu: float = 0, sigma: float = 1) -> float:
    """The probability that an N(mu, sigma) is not between lo and hi."""
    return 1 - normal_probability_between(lo, hi, mu, sigma)

def normal_upper_bound(probability: float, mu: float = 0, sigma: float = 1) -> float:
    """Returns the z for which P(Z <= z) = probability"""
    return inverse_normal_cdf(probability, mu, sigma)

def normal_lower_bound(probability: float, mu: float = 0, sigma: float = 1) -> float:
    """Returns the z for which P(Z >= z) = probability"""
    return inverse_normal_cdf(1 - probability, mu, sigma)

def normal_two_sided_bounds(probability: float, mu: float = 0, sigma: float = 1) -> Tuple[float, float]:
    """Returns the symmetric (about the mean) bounds that contain the specified probability"""
    tail_probability = (1 - probability) / 2
    # upper bound should have tail_probability above it
    upper_bound = normal_lower_bound(tail_probability, mu, sigma)
    # lower bound should have tail_probability below it
    lower_bound = normal_upper_bound(tail_probability, mu, sigma)
    return lower_bound, upper_bound

mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)
lower_bound, upper_bound = normal_two_sided_bounds(0.95, mu_0, sigma_0)

# 95% bounds based on assumption p is 0.5
lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)

# an actual mu and sigma based on p = 0.55
mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)

# a type 2 error means we fail to reject the null hypothesis,
# which will happen when X is still in our original interval
type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)
power = 1 - type_2_probability


WITH EXAMPLE 

from typing import Tuple
import math
from scratch.probability import normal_cdf, normal_probability_between

def normal_approximation_to_binomial(n: int, p: float) -> Tuple[float, float]:
    """Returns mu and sigma corresponding to a Binomial(n, p)"""
    mu = p * n
    sigma = math.sqrt(p * (1 - p) * n)
    return mu, sigma

def normal_two_sided_bounds(probability: float, mu: float = 0, sigma: float = 1) -> Tuple[float, float]:
    """Returns the symmetric (about the mean) bounds that contain the specified probability"""
    tail_probability = (1 - probability) / 2

    # Upper bound should have tail probability above it
    upper_bound = normal_lower_bound(tail_probability, mu, sigma)

    # Lower bound should have tail probability below it
    lower_bound = normal_upper_bound(tail_probability, mu, sigma)

    return lower_bound, upper_bound

def normal_power(n: int, p: float, lo: float, hi: float, mu_1: float, sigma_1: float) -> float:
    """Calculates the power of a hypothesis test"""
    type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)
    power = 1 - type_2_probability
    return power

# Example usage
mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)
lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)
mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)
power = normal_power(1000, 0.5, lo, hi, mu_1, sigma_1)

print("Power:", power)




P Values 

def two_sided_pvalue(x: float, mu: float = 0, sigma: float = 1) -> float:
    if x >= mu:
        # x is greater than the mean, so the tail is everything greater than x
        return 2 * normal_probability_above(x, mu, sigma)
    else:
        # x is less than the mean, so the tail is everything less than x
        return 2 * normal_probability_below(x, mu, sigma)

two_sided_pvalue(529.5, mu=0, sigma=1)  # 0.062

import random

extreme_value_count = 0
for _ in range(1000):
    num_heads = sum(1 if random.random() < 0.5 else 0 for _ in range(1000))
    if num_heads >= 530 or num_heads <= 470:
        extreme_value_count += 1

# p-value was 0.062 => ~62 extreme values out of 1000
assert 59 < extreme_value_count < 65, f"{extreme_value_count}"



In the code above:

two_sided_pvalue(x, mu, sigma): This function calculates the two-sided p-value for a given x value in a normal distribution with mean mu and standard deviation sigma. If x is greater than or equal to mu, it calculates the tail probability above x using normal_probability_above and doubles it (since it's a two-sided test). Otherwise, if x is less than mu, it calculates the tail probability below x using normal_probability_below and doubles it. The resulting p-value is returned.

extreme_value_count: This variable keeps track of the count of extreme values in a binomial distribution experiment. In each iteration of the loop, it generates 1000 random numbers between 0 and 1 using random.random() and counts the number of heads (values less than 0.5) in the sequence. If the number of heads is either greater than or equal to 530 or less than or equal to 470, it increments the extreme_value_count by 1.

The final assertion checks that the extreme_value_count falls within the expected range of 59 to 65, indicating that the experiment generated approximately 62 extreme values out of 1000 trials.
