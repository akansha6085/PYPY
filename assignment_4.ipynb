{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a python program to randomly generate data with 100 numbers and form a\n",
        "histogram of it. Range of numbers should be between 1 to 100(both included), bucket\n",
        "size=10."
      ],
      "metadata": {
        "id": "AQkzo8cwZ5Ki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoVQoGHoZz6s"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generateRandomNumbers(number, start, end):\n",
        "    random_numbers = []\n",
        "    for i in range(number):\n",
        "        random_numbers.append(random.randint(start, end))\n",
        "    return random_numbers\n",
        "\n",
        "def main():\n",
        "    number, start, end = 100, 1, 100\n",
        "    random_numbers = generateRandomNumbers(number, start, end)\n",
        "    print('Generated Random Numbers:', random_numbers)\n",
        "\n",
        "    plt.hist(random_numbers, bins=10, color='pink', edgecolor='red')\n",
        "    plt.xlabel('Generated Random Numbers Range 1 to 100 Including')\n",
        "    plt.ylabel('Frequency Count')\n",
        "    plt.title('Generated Random Numbers Range 1 to 100 Including Vs Frequency Count')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a python program to create a NamedTuple with following details (Roll\n",
        "No.,[Name,Branch,Year of Admission])."
      ],
      "metadata": {
        "id": "Cu3R9MOCaDDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "def generateNamedTuple():\n",
        "    Roll_No = namedtuple(\"Roll_No\", [\"Name\", \"Branch\", \"Year_Of_Admission\"])\n",
        "    Roll = []\n",
        "    R1 = Roll_No('Rahul', 'C.S.E.', 2017)\n",
        "    Roll.append(R1)\n",
        "    R2 = Roll_No('Dabba', 'C.S.E.', 2018)\n",
        "    Roll.append(R2)\n",
        "    R3 = Roll_No('Soumya', 'C.S.E.', 2019)\n",
        "    Roll.append(R3)\n",
        "    R4 = Roll_No('Rituraj', 'C.S.E.', 2020)\n",
        "    Roll.append(R4)\n",
        "    return Roll\n",
        "\n",
        "def main():\n",
        "    Roll_No = generateNamedTuple()\n",
        "    print('Named Tuple: Roll_No')\n",
        "    for Roll in Roll_No:\n",
        "        print(Roll)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "jTG_H_4IaKat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a python program to create a Dataclass with following details (Roll\n",
        "No.,[Name,Branch,Year of Admission])."
      ],
      "metadata": {
        "id": "TmQmdR_EaLRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Roll_No:\n",
        "    name: str\n",
        "    branch: str\n",
        "    year_of_admission: int\n",
        "\n",
        "def generateDataclass():\n",
        "    Roll = []\n",
        "    R1 = Roll_No('Rahul', 'C.S.E.', 2017)\n",
        "    Roll.append(R1)\n",
        "    R2 = Roll_No('Dabba', 'C.S.E.', 2018)\n",
        "    Roll.append(R2)\n",
        "    R3 = Roll_No('Soumya', 'C.S.E.', 2019)\n",
        "    Roll.append(R3)\n",
        "    R4 = Roll_No('Rituraj', 'C.S.E.', 2020)\n",
        "    Roll.append(R4)\n",
        "    return Roll\n",
        "\n",
        "def main():\n",
        "    print('Dataclass:Roll_No')\n",
        "    Roll = generateDataclass()\n",
        "    for R in Roll:\n",
        "        print(R)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "5VpWwARzaNox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write, execute and visualise the progress of a python code using tqdm module with\n",
        "setting proper description."
      ],
      "metadata": {
        "id": "dT8HTLftaZx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "def primes_up_to(n):\n",
        "    primes = []\n",
        "    with tqdm.trange(2, n) as t:\n",
        "        for i in t:\n",
        "            i_is_prime = not any(i % p == 0 for p in primes)\n",
        "            if i_is_prime:\n",
        "                primes.append(i)\n",
        "            t.set_description(f'{len(primes)} Primes')\n",
        "    return primes\n",
        "\n",
        "def main():\n",
        "    primes = primes_up_to(1000)\n",
        "    print(primes)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "rrRmamL3ab5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a python program to split the data ’X’ into test and train dataset and print them,\n",
        "use 70-30 split criteria."
      ],
      "metadata": {
        "id": "E9jAXmvPai5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def loadDataset():\n",
        "    with open('Advertising.csv') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        header = []\n",
        "        header = next(csv_reader)\n",
        "        print('Header:', header)\n",
        "        rows = []\n",
        "        for row in csv_reader:\n",
        "            rows.append(row)\n",
        "        return rows\n",
        "\n",
        "def main():\n",
        "    data_set = loadDataset()\n",
        "    print('No. Of Rows Before Split In A Data Set:', len(data_set))\n",
        "    Advertising_train, Advertising_test = train_test_split(data_set, test_size=0.30)\n",
        "    print('No. Of Rows After Split In A Train Data Set:', len(Advertising_train))\n",
        "    print('No. Of Rows After Split In A Test Data Set:', len(Advertising_test))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "AGAOKCY4anf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Given below is a confusion matrix, compute Precision, Recall, Accuracy and f1 score.\n",
        "\n",
        "Write a python program using a generic function to compute above given parameters by\n",
        "taking values of TP, FP, TN, FN as user input."
      ],
      "metadata": {
        "id": "YXaB0BEeapUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(TP, FP, FN, TN):\n",
        "    return TP / (TP + FP)\n",
        "\n",
        "def recall(TP, FP, FN, TN):\n",
        "    return TP / (TP + FN)\n",
        "\n",
        "def accuracy(TP, FP, FN, TN):\n",
        "    correct = TP + TN\n",
        "    total = TP + FP + FN + TN\n",
        "    return correct / total\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "def genericFunction(TP, FP, FN, TN):\n",
        "    p = precision(TP, FP, FN, TN)\n",
        "    r = recall(TP, FP, FN, TN)\n",
        "    a = accuracy(TP, FP, FN, TN)\n",
        "    f1 = f1_score(p, r)\n",
        "    print('Precision:', p)\n",
        "    print('Recall:', r)\n",
        "    print('Accuracy:', a)\n",
        "    print('F1 Score:', f1)\n",
        "\n",
        "def main():\n",
        "    TP, FP, FN, TN = 250, 750, 500, 250\n",
        "    print('From Given Confusion Matrix Data,')\n",
        "    genericFunction(TP, FP, FN, TN)\n",
        "    TP = int(input('Enter TP Value: '))\n",
        "    FP = int(input('Enter FP Value: '))\n",
        "    FN = int(input('Enter FN Value: '))\n",
        "    TN = int(input('Enter TN Value: '))\n",
        "    print('From Given User Input Data,')\n",
        "    genericFunction(TP, FP, FN, TN)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "FzM2vLKIaraz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write the python program for k-NN model implemented on iris dataset and print\n",
        "accuracy of the same."
      ],
      "metadata": {
        "id": "w_oF5uyxa3WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import random\n",
        "import math\n",
        "from typing import NamedTuple, List, Tuple, Dict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "Vector = List[float]\n",
        "\n",
        "class LabeledPoint(NamedTuple):\n",
        "    point: Vector\n",
        "    label: str\n",
        "\n",
        "def majority_vote(labels):\n",
        "    vote_counts = Counter(labels)\n",
        "    winner, winner_count = vote_counts.most_common(1)[0]\n",
        "    num_winners = len([count for count in vote_counts.values() if count == winner_count])\n",
        "    if num_winners == 1:\n",
        "        return winner\n",
        "    else:\n",
        "        return majority_vote(labels[:-1])\n",
        "\n",
        "def knn_classify(k, labeled_points, new_points):\n",
        "    by_distance = sorted(labeled_points, key=lambda lp: distance(lp.point, new_points))\n",
        "    k_nearest_labels = [lp.label for lp in by_distance[:k]]\n",
        "    return majority_vote(k_nearest_labels)\n",
        "\n",
        "def dot(v, w):\n",
        "    assert len(v) == len(w)\n",
        "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
        "\n",
        "def sum_of_squares(v):\n",
        "    return dot(v, v)\n",
        "\n",
        "def magnitude(v):\n",
        "    return math.sqrt(sum_of_squares(v))\n",
        "\n",
        "def subtract(v, w):\n",
        "    assert len(v) == len(w)\n",
        "    return [v_i - w_i for v_i, w_i in zip(v, w)]\n",
        "\n",
        "def distance(v, w):\n",
        "    return magnitude(subtract(v, w))\n",
        "\n",
        "def parse_iris_row(row: List[str]):\n",
        "    measurements = [float(value) for value in row[:-1]]\n",
        "    label = row[-1].split(\"-\")[-1]\n",
        "    return LabeledPoint(measurements, label)\n",
        "\n",
        "def main():\n",
        "    data = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\")\n",
        "\n",
        "    with open('iris.dat', 'w') as f:\n",
        "        f.write(data.text)\n",
        "\n",
        "    with open('iris.data') as f:\n",
        "        reader = csv.reader(f)\n",
        "        iris_data = [parse_iris_row(row) for row in reader if row != []]\n",
        "\n",
        "    random.seed(12)\n",
        "    iris_train, iris_test = train_test_split(iris_data, test_size=0.30)\n",
        "\n",
        "    assert len(iris_train) == 0.7 * 150\n",
        "    assert len(iris_test) == 0.3 * 150\n",
        "\n",
        "    confusion_matrix: Dict[Tuple[str, str], int] = defaultdict(int)\n",
        "    num_correct = 0\n",
        "\n",
        "    for iris in iris_test:\n",
        "        predict = knn_classify(5, iris_train, iris.point)\n",
        "        actual = iris.label\n",
        "        if predict == actual:\n",
        "            num_correct += 1\n",
        "        confusion_matrix[(predict, actual)] += 1\n",
        "\n",
        "    pct_correct = num_correct / len(iris_test)\n",
        "    print(pct_correct, confusion_matrix)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "m6RfeUHza38b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is curse of dimensionality? Write a python program to show it by calculating\n",
        "minimum distances between points when dimensions increase."
      ],
      "metadata": {
        "id": "7vqKuG_2bGfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The curse of dimensionality refers to the phenomena that occur when classifying,\n",
        "organizing, and analyzing high dimensional data that does not occur in low dimensional\n",
        "spaces, specifically the issue of data sparsity and “closeness” of data."
      ],
      "metadata": {
        "id": "rQ1CQB8IbLs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dot(v, w):\n",
        "    assert len(v) == len(w)\n",
        "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
        "\n",
        "def sum_of_squares(v):\n",
        "    return dot(v, v)\n",
        "\n",
        "def magnitude(v):\n",
        "    return math.sqrt(sum_of_squares(v))\n",
        "\n",
        "def subtract(v, w):\n",
        "    assert len(v) == len(w)\n",
        "    return [v_i - w_i for v_i, w_i in zip(v, w)]\n",
        "\n",
        "def distance(v, w):\n",
        "    return magnitude(subtract(v, w))\n",
        "\n",
        "def random_point(dim):\n",
        "    return [random.random() for _ in range(dim)]\n",
        "\n",
        "def random_distance(dim, num_pairs):\n",
        "    return [distance(random_point(dim), random_point(dim)) for _ in range(num_pairs)]\n",
        "\n",
        "def main():\n",
        "    dimensions = range(1, 101)\n",
        "    avg_distances, min_distances = [], []\n",
        "    random.seed(0)\n",
        "\n",
        "    for dim in tqdm.tqdm(dimensions, desc='Curse Of Dimensionality'):\n",
        "        distances = random_distance(dim, 10000)\n",
        "        avg_distances.append(sum(distances) / 10000)\n",
        "        min_distances.append(min(distances))\n",
        "\n",
        "    min_avg_ratio = [min_dist / avg_dist for min_dist, avg_dist in zip(min_distances, avg_distances)]\n",
        "\n",
        "    plt.xlabel('No. Of Dimensions')\n",
        "    plt.ylabel('Distance')\n",
        "    plt.plot(dimensions, avg_distances, label='Average Distance')\n",
        "    plt.plot(dimensions, min_distances, label='Minimum Distance')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.xlabel('No. Of Dimensions')\n",
        "    plt.ylabel('Distance')\n",
        "    plt.plot(dimensions, min_avg_ratio, label='Minimum Distance/Average Distance')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "dNC8mR3EbHKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}